{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8ec9d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "loading annotations into memory...\n",
      "Done (t=4.88s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.23s)\n",
      "creating index...\n",
      "index created!\n",
      "Evaluating FRCNN before training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval FRCNN (COCO mAP): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:06<00:00, 15.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.02s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.05s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      "Initial metrics: {'AP': 0.0, 'AP50': 0.0, 'AP75': 0.0, 'APs': 0.0, 'APm': 0.0, 'APl': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train FRCNN: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:22<00:00,  3.01it/s]\n",
      "Eval FRCNN (COCO mAP): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:06<00:00, 15.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.17s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.038\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.074\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.026\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.039\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.080\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.060\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.031\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.058\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.065\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.056\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.119\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.086\n",
      "Epoch 1/6 | train_loss=1.2323 | AP=0.0377 | AP50=0.0738 | AP75=0.0259 | APs=0.0390 | APm=0.0804 | APl=0.0601\n",
      "  -> New best FRCNN model saved (AP=0.0377)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train FRCNN: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:23<00:00,  3.01it/s]\n",
      "Eval FRCNN (COCO mAP): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:06<00:00, 15.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.16s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.10s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.124\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.293\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.072\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.085\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.184\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.158\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.200\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.204\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.123\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.273\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.261\n",
      "Epoch 2/6 | train_loss=0.9524 | AP=0.1243 | AP50=0.2930 | AP75=0.0722 | APs=0.0847 | APm=0.1842 | APl=0.1577\n",
      "  -> New best FRCNN model saved (AP=0.1243)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train FRCNN: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:23<00:00,  2.99it/s]\n",
      "Eval FRCNN (COCO mAP): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:06<00:00, 15.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.17s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.10s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.157\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.341\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.114\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.125\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.213\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.206\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.128\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.231\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.241\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.165\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.284\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.324\n",
      "Epoch 3/6 | train_loss=0.7799 | AP=0.1572 | AP50=0.3411 | AP75=0.1144 | APs=0.1252 | APm=0.2131 | APl=0.2059\n",
      "  -> New best FRCNN model saved (AP=0.1572)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train FRCNN: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:23<00:00,  3.00it/s]\n",
      "Eval FRCNN (COCO mAP): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:06<00:00, 15.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.15s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.10s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.228\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.416\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.226\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.311\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.307\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.176\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.309\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.322\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.213\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.386\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.431\n",
      "Epoch 4/6 | train_loss=0.5796 | AP=0.2279 | AP50=0.4157 | AP75=0.2257 | APs=0.1657 | APm=0.3113 | APl=0.3072\n",
      "  -> New best FRCNN model saved (AP=0.2279)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train FRCNN: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:24<00:00,  2.95it/s]\n",
      "Eval FRCNN (COCO mAP): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:06<00:00, 15.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.15s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.10s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.238\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.431\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.228\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.166\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.311\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.341\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.187\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.315\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.328\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.211\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.375\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.459\n",
      "Epoch 5/6 | train_loss=0.4900 | AP=0.2376 | AP50=0.4308 | AP75=0.2284 | APs=0.1658 | APm=0.3114 | APl=0.3406\n",
      "  -> New best FRCNN model saved (AP=0.2376)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train FRCNN: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [01:23<00:00,  2.99it/s]\n",
      "Eval FRCNN (COCO mAP): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:06<00:00, 15.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.14s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.10s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.441\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.243\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.157\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.328\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.354\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.320\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.331\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.196\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.390\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.463\n",
      "Epoch 6/6 | train_loss=0.4499 | AP=0.2465 | AP50=0.4413 | AP75=0.2429 | APs=0.1571 | APm=0.3285 | APl=0.3536\n",
      "  -> New best FRCNN model saved (AP=0.2465)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Subset\n",
    "from tqdm import tqdm\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "from src.utils.coco_utils import make_coco_loaders\n",
    "from src.models.frcnn import get_frcnn_model\n",
    "\n",
    "\n",
    "def get_coco_api_from_loader(loader):\n",
    "    \"\"\"\n",
    "    Robustly get the underlying pycocotools COCO object from a DataLoader.\n",
    "    \"\"\"\n",
    "    ds = loader.dataset\n",
    "    for _ in range(10):\n",
    "        if hasattr(ds, \"coco\"):\n",
    "            return ds.coco\n",
    "        if hasattr(ds, \"dataset\"):\n",
    "            ds = ds.dataset\n",
    "        else:\n",
    "            break\n",
    "    raise AttributeError(\n",
    "        \"Could not find 'coco' attribute in dataset. \"\n",
    "        \"Please check make_coco_loaders implementation.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def get_img_ids_for_loader(loader):\n",
    "    \"\"\"\n",
    "    Build a list img_ids such that:\n",
    "        img_ids[i] = COCO image_id corresponding to loader.dataset[i]\n",
    "\n",
    "    Handles Subset and simple wrappers. Assumes val_loader has shuffle=False.\n",
    "    \"\"\"\n",
    "    ds = loader.dataset\n",
    "    indices = None  # indices in the base dataset\n",
    "\n",
    "    while True:\n",
    "        if isinstance(ds, Subset):\n",
    "            if indices is None:\n",
    "                indices = list(ds.indices)\n",
    "            else:\n",
    "                indices = [indices[i] for i in ds.indices]\n",
    "            ds = ds.dataset\n",
    "            continue\n",
    "\n",
    "        if not hasattr(ds, \"coco\") and hasattr(ds, \"dataset\"):\n",
    "            ds = ds.dataset\n",
    "            continue\n",
    "\n",
    "        break\n",
    "\n",
    "    if not hasattr(ds, \"coco\"):\n",
    "        raise RuntimeError(\n",
    "            \"Could not find a base COCO dataset with a 'coco' attribute under loader.dataset\"\n",
    "        )\n",
    "\n",
    "    base_ds = ds\n",
    "    coco = base_ds.coco\n",
    "\n",
    "    if indices is None:\n",
    "        indices = list(range(len(base_ds)))\n",
    "\n",
    "    if hasattr(base_ds, \"ids\"):\n",
    "        base_img_ids = list(base_ds.ids)\n",
    "    else:\n",
    "        base_img_ids = list(sorted(coco.getImgIds()))\n",
    "\n",
    "    loader_img_ids = [int(base_img_ids[i]) for i in indices]\n",
    "    return loader_img_ids\n",
    "\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, targets in tqdm(loader, desc=\"Train FRCNN\"):\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += losses.item()\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_coco_mAP(model, loader, device):\n",
    "    \"\"\"\n",
    "    Run COCO-style evaluation on *your subset* of val2017.\n",
    "    Returns dict with AP, AP50, AP75, APs, APm, APl.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    coco = get_coco_api_from_loader(loader)\n",
    "    coco_img_ids_all = set(coco.getImgIds())\n",
    "\n",
    "    # Map loader idx -> true COCO image_id (for the subset)\n",
    "    loader_img_ids = get_img_ids_for_loader(loader)\n",
    "    assert len(loader_img_ids) == len(loader.dataset), \\\n",
    "        \"Length mismatch between loader_img_ids and loader.dataset\"\n",
    "\n",
    "    results = []\n",
    "    global_idx = 0\n",
    "\n",
    "    for images, targets in tqdm(loader, desc=\"Eval FRCNN (COCO mAP)\"):\n",
    "        images = [img.to(device) for img in images]\n",
    "        outputs = model(images)\n",
    "\n",
    "        batch_size = len(outputs)\n",
    "        batch_img_ids = loader_img_ids[global_idx: global_idx + batch_size]\n",
    "        global_idx += batch_size\n",
    "\n",
    "        for img_id, output in zip(batch_img_ids, outputs):\n",
    "            if img_id not in coco_img_ids_all:\n",
    "                continue\n",
    "\n",
    "            boxes = output[\"boxes\"].detach().cpu()\n",
    "            scores = output[\"scores\"].detach().cpu()\n",
    "            labels = output[\"labels\"].detach().cpu()\n",
    "\n",
    "            if boxes.numel() == 0:\n",
    "                continue\n",
    "\n",
    "            # xyxy -> xywh\n",
    "            boxes_xywh = boxes.clone()\n",
    "            boxes_xywh[:, 2] = boxes[:, 2] - boxes[:, 0]\n",
    "            boxes_xywh[:, 3] = boxes[:, 3] - boxes[:, 1]\n",
    "\n",
    "            for box, score, label in zip(boxes_xywh, scores, labels):\n",
    "                results.append(\n",
    "                    {\n",
    "                        \"image_id\": int(img_id),\n",
    "                        \"category_id\": int(label),  # your dataset already uses COCO cat_ids\n",
    "                        \"bbox\": box.tolist(),\n",
    "                        \"score\": float(score),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    if not results:\n",
    "        print(\"No detections to evaluate.\")\n",
    "        return None\n",
    "\n",
    "    coco_dt = coco.loadRes(results)\n",
    "    coco_eval = COCOeval(coco, coco_dt, iouType=\"bbox\")\n",
    "\n",
    "    # evaluate only on images we actually predicted on\n",
    "    eval_img_ids = sorted({r[\"image_id\"] for r in results})\n",
    "    coco_eval.params.imgIds = eval_img_ids\n",
    "\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "\n",
    "    metrics = {\n",
    "        \"AP\": float(coco_eval.stats[0]),\n",
    "        \"AP50\": float(coco_eval.stats[1]),\n",
    "        \"AP75\": float(coco_eval.stats[2]),\n",
    "        \"APs\": float(coco_eval.stats[3]),\n",
    "        \"APm\": float(coco_eval.stats[4]),\n",
    "        \"APl\": float(coco_eval.stats[5]),\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Main: data, model, optimizer, training + validation + COCO mAP\n",
    "# ------------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "train_loader, val_loader = make_coco_loaders(\n",
    "    root=\"/mnt/ssd2/santana-coco/data/coco\",\n",
    "    batch_size=2,\n",
    "    num_workers=4,\n",
    "    train_limit=500,   # None for full train2017 per proposal\n",
    "    val_limit=100,     # None for full val2017 per proposal\n",
    ")\n",
    "\n",
    "num_classes = 91  # standard COCO setting (incl. background)\n",
    "model = get_frcnn_model(num_classes=num_classes).to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "scheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "num_epochs = 6  # short run due to limited GPU\n",
    "best_ap = 0.0\n",
    "\n",
    "# (Optional sanity check: evaluate pre-trained model before training)\n",
    "print(\"Evaluating FRCNN before training...\")\n",
    "metrics0 = evaluate_coco_mAP(model, val_loader, device)\n",
    "print(\"Initial metrics:\", metrics0)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, device)\n",
    "    scheduler.step()\n",
    "\n",
    "    metrics = evaluate_coco_mAP(model, val_loader, device)\n",
    "    if metrics is not None:\n",
    "        ap = metrics[\"AP\"]\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1}/{num_epochs} | \"\n",
    "            f\"train_loss={train_loss:.4f} | \"\n",
    "            f\"AP={ap:.4f} | AP50={metrics['AP50']:.4f} | \"\n",
    "            f\"AP75={metrics['AP75']:.4f} | APs={metrics['APs']:.4f} | \"\n",
    "            f\"APm={metrics['APm']:.4f} | APl={metrics['APl']:.4f}\"\n",
    "        )\n",
    "\n",
    "        if ap > best_ap:\n",
    "            best_ap = ap\n",
    "            torch.save(model.state_dict(), \"frcnn_best.pth\")\n",
    "            print(f\"  -> New best FRCNN model saved (AP={ap:.4f})\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1}/{num_epochs} | \"\n",
    "            f\"train_loss={train_loss:.4f} | no detections on val set\"\n",
    "        )\n",
    "\n",
    "    torch.save(model.state_dict(), f\"frcnn_epoch{epoch + 1}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e516b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.233 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.231 üöÄ Python-3.12.3 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4060, 7814MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data/coco_subset.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=6, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8s_640_subset10, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/coco, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/home/santana/MyStuff/assignments/dl-final-project/runs/coco/yolov8s_640_subset10, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=4, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \n",
      "Model summary: 129 layers, 11,166,560 parameters, 11,166,544 gradients, 28.8 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 4692.8¬±1610.6 MB/s, size: 98.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /mnt/ssd2/santana-coco/data/coco_subset_500_100/labels/train.cache... 500 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 500/500 476.3Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 3566.0¬±1638.0 MB/s, size: 110.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/ssd2/santana-coco/data/coco_subset_500_100/labels/val.cache... 100 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 100/100 346.1Kit/s 0.0s\n",
      "Plotting labels to /home/santana/MyStuff/assignments/dl-final-project/runs/coco/yolov8s_640_subset10/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1m/home/santana/MyStuff/assignments/dl-final-project/runs/coco/yolov8s_640_subset10\u001b[0m\n",
      "Starting training for 6 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        1/6      3.87G      1.092      1.026      1.202         80        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 32/32 5.2it/s 6.2s0.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 8.5it/s 0.5s0.2s\n",
      "                   all        100        860      0.663      0.662      0.705      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        2/6       3.8G      1.061     0.9644      1.151         95        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 32/32 5.5it/s 5.8s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 9.3it/s 0.4s0.2s\n",
      "                   all        100        860      0.657      0.648      0.684       0.52\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        3/6      3.81G      1.058     0.9828      1.155         40        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 32/32 5.5it/s 5.8s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 9.3it/s 0.4s0.2s\n",
      "                   all        100        860      0.692      0.604      0.671      0.506\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        4/6      4.01G     0.9775     0.9126      1.118         38        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 32/32 5.6it/s 5.7s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 9.4it/s 0.4s0.2s\n",
      "                   all        100        860      0.709      0.597      0.672      0.505\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        5/6      3.88G      1.001     0.8908      1.122         58        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 32/32 5.5it/s 5.8s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 9.3it/s 0.4s0.2s\n",
      "                   all        100        860      0.699      0.607      0.665      0.501\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K        6/6      3.83G     0.9521     0.8667      1.105         44        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 32/32 5.6it/s 5.7s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 9.4it/s 0.4s0.2s\n",
      "                   all        100        860      0.686      0.614      0.663      0.506\n",
      "\n",
      "6 epochs completed in 0.011 hours.\n",
      "Optimizer stripped from /home/santana/MyStuff/assignments/dl-final-project/runs/coco/yolov8s_640_subset10/weights/last.pt, 22.6MB\n",
      "Optimizer stripped from /home/santana/MyStuff/assignments/dl-final-project/runs/coco/yolov8s_640_subset10/weights/best.pt, 22.6MB\n",
      "\n",
      "Validating /home/santana/MyStuff/assignments/dl-final-project/runs/coco/yolov8s_640_subset10/weights/best.pt...\n",
      "Ultralytics 8.3.231 üöÄ Python-3.12.3 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4060, 7814MiB)\n",
      "Model summary (fused): 72 layers, 11,156,544 parameters, 0 gradients, 28.6 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 4/4 6.2it/s 0.6s0.3s\n",
      "                   all        100        860      0.663      0.663      0.705      0.546\n",
      "                person         54        288      0.827      0.684       0.79      0.547\n",
      "               bicycle          2          2      0.488          1      0.995      0.672\n",
      "                   car         11         32       0.82      0.531      0.694      0.475\n",
      "            motorcycle          1          2      0.508        0.5      0.497      0.447\n",
      "              airplane          3          4      0.918       0.75      0.945      0.815\n",
      "                   bus          3          5       0.72          1      0.995      0.972\n",
      "                 train          4          5      0.887          1      0.995      0.876\n",
      "                 truck          5         11      0.465      0.319      0.446        0.3\n",
      "                  boat          1          1      0.572          1      0.995      0.302\n",
      "         traffic light          4         10      0.736       0.56      0.749      0.426\n",
      "          fire hydrant          1          1      0.696          1      0.995      0.995\n",
      "             stop sign          1          1      0.661          1      0.995      0.895\n",
      "         parking meter          1          1      0.315          1      0.332      0.265\n",
      "                 bench          5          9          1      0.217        0.4      0.275\n",
      "                  bird          5         24       0.78      0.917      0.877      0.618\n",
      "                   cat          3          3      0.557      0.667      0.676      0.626\n",
      "                   dog          4          4      0.796      0.978      0.945       0.82\n",
      "                 horse          2          6      0.821        0.5      0.623      0.564\n",
      "                 sheep          2          7          0          0     0.0119     0.0082\n",
      "                   cow          4         15      0.753        0.8      0.839      0.636\n",
      "              elephant          1          1      0.672          1      0.995      0.995\n",
      "                  bear          1          1      0.689          1      0.995      0.995\n",
      "                 zebra          2          5      0.814      0.881      0.962      0.723\n",
      "               giraffe          2         15      0.788      0.933      0.943      0.556\n",
      "              backpack          5          9      0.743      0.325      0.413      0.149\n",
      "              umbrella          3          3      0.664          1      0.913      0.619\n",
      "               handbag          5          9      0.633      0.222      0.233      0.133\n",
      "                   tie          1          1          0          0     0.0163    0.00652\n",
      "              suitcase          1          5      0.679          1      0.962      0.558\n",
      "               frisbee          1          1      0.935          1      0.995      0.895\n",
      "                  skis          1          4      0.805        0.5       0.54      0.457\n",
      "           sports ball          7          8      0.615      0.375      0.538      0.309\n",
      "                  kite          4         16      0.736      0.375       0.47      0.318\n",
      "          baseball bat          5          9      0.605      0.341      0.407      0.252\n",
      "        baseball glove          5          7      0.791      0.714      0.761       0.55\n",
      "             surfboard          4          5      0.634        0.6      0.728      0.541\n",
      "         tennis racket          2          3      0.538          1      0.913      0.692\n",
      "                bottle         12         35      0.784      0.629      0.701      0.451\n",
      "            wine glass          4          7      0.483      0.429      0.366      0.239\n",
      "                   cup          9         26      0.797      0.654      0.765      0.584\n",
      "                  fork          1          2      0.716        0.5      0.528       0.45\n",
      "                 knife          3          3      0.741      0.667      0.731      0.588\n",
      "                 spoon          7         12       0.76      0.167      0.462      0.225\n",
      "                  bowl         10         18      0.729      0.597      0.724      0.492\n",
      "                banana          4         17      0.501      0.354      0.491      0.333\n",
      "                 apple          1          4      0.967       0.75      0.773      0.652\n",
      "              sandwich          1          2      0.286          1      0.995      0.796\n",
      "                orange          1          1      0.681          1      0.995      0.895\n",
      "              broccoli          1          2          1      0.862      0.995      0.746\n",
      "                carrot          2          5      0.254      0.281      0.219      0.139\n",
      "               hot dog          4         10      0.874        0.6      0.721      0.533\n",
      "                 pizza          5          5          1      0.708      0.906       0.56\n",
      "                 donut          1          1       0.13          1      0.995      0.995\n",
      "                  cake          5         11      0.422      0.455      0.506      0.446\n",
      "                 chair         15         57      0.734      0.436      0.543      0.371\n",
      "                 couch          4          4      0.754          1      0.995      0.685\n",
      "          potted plant          6          9      0.232      0.111      0.278      0.167\n",
      "                   bed          3          3      0.615      0.667      0.708      0.647\n",
      "          dining table         10         14      0.527      0.636      0.601       0.53\n",
      "                toilet          3          3      0.711          1      0.995      0.864\n",
      "                    tv          5          7          1      0.411      0.513      0.433\n",
      "                laptop          3          5      0.708        0.8      0.886      0.823\n",
      "                 mouse          3          3       0.63      0.667      0.452      0.419\n",
      "                remote          3          6      0.618        0.5      0.644      0.495\n",
      "              keyboard          3          4          1        0.5      0.845      0.769\n",
      "            cell phone          6          7       0.51      0.286      0.397      0.272\n",
      "             microwave          3          3      0.776          1      0.995      0.863\n",
      "                  oven          5          7      0.778      0.571      0.619      0.431\n",
      "               toaster          1          1      0.714          1      0.995      0.597\n",
      "                  sink          6          7      0.609      0.429      0.679      0.401\n",
      "          refrigerator          4         12          1      0.326      0.486      0.314\n",
      "                  book          2          2      0.344        0.5      0.373      0.341\n",
      "                 clock          2          2      0.691          1      0.995       0.92\n",
      "                  vase          6          7      0.403      0.286      0.459      0.339\n",
      "              scissors          1          1      0.624          1      0.995      0.995\n",
      "            teddy bear          2          2      0.629      0.887      0.663      0.392\n",
      "Speed: 0.1ms preprocess, 2.9ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1m/home/santana/MyStuff/assignments/dl-final-project/runs/coco/yolov8s_640_subset10\u001b[0m\n",
      "Ultralytics 8.3.231 üöÄ Python-3.12.3 torch-2.9.1+cu128 CUDA:0 (NVIDIA GeForce RTX 4060, 7814MiB)\n",
      "Model summary (fused): 72 layers, 11,156,544 parameters, 0 gradients, 28.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 5639.2¬±2234.9 MB/s, size: 154.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /mnt/ssd2/santana-coco/data/coco_subset_500_100/labels/val.cache... 100 images, 0 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 100/100 529.6Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 7/7 6.6it/s 1.1s0.2s\n",
      "                   all        100        860      0.661      0.668      0.703      0.545\n",
      "                person         54        288       0.83      0.693      0.789      0.549\n",
      "               bicycle          2          2      0.486          1      0.995      0.672\n",
      "                   car         11         32      0.774      0.531      0.699       0.48\n",
      "            motorcycle          1          2      0.501        0.5      0.497      0.447\n",
      "              airplane          3          4      0.912       0.75      0.945      0.815\n",
      "                   bus          3          5      0.872          1      0.995      0.972\n",
      "                 train          4          5      0.885          1      0.995      0.876\n",
      "                 truck          5         11      0.507      0.375      0.493      0.333\n",
      "                  boat          1          1      0.561          1      0.995      0.302\n",
      "         traffic light          4         10      0.736      0.561      0.738      0.415\n",
      "          fire hydrant          1          1      0.693          1      0.995      0.895\n",
      "             stop sign          1          1      0.657          1      0.995      0.895\n",
      "         parking meter          1          1      0.313          1      0.332      0.265\n",
      "                 bench          5          9          1      0.213      0.401      0.251\n",
      "                  bird          5         24      0.776      0.917      0.877       0.62\n",
      "                   cat          3          3      0.556      0.667      0.676      0.626\n",
      "                   dog          4          4          1      0.995      0.995      0.822\n",
      "                 horse          2          6      0.818        0.5      0.615      0.553\n",
      "                 sheep          2          7          0          0     0.0122    0.00789\n",
      "                   cow          4         15      0.736        0.8      0.839      0.636\n",
      "              elephant          1          1      0.668          1      0.995      0.995\n",
      "                  bear          1          1      0.685          1      0.995      0.995\n",
      "                 zebra          2          5      0.815      0.888      0.962      0.723\n",
      "               giraffe          2         15      0.784      0.933      0.943      0.555\n",
      "              backpack          5          9       0.75      0.333      0.409      0.152\n",
      "              umbrella          3          3       0.63          1      0.913      0.619\n",
      "               handbag          5          9       0.59      0.222      0.231      0.133\n",
      "                   tie          1          1          0          0      0.016    0.00642\n",
      "              suitcase          1          5      0.667          1      0.962      0.558\n",
      "               frisbee          1          1      0.924          1      0.995      0.895\n",
      "                  skis          1          4      0.801        0.5       0.54      0.457\n",
      "           sports ball          7          8      0.611      0.375      0.527      0.303\n",
      "                  kite          4         16      0.707      0.375      0.425      0.314\n",
      "          baseball bat          5          9       0.61      0.351      0.408      0.253\n",
      "        baseball glove          5          7      0.787      0.714      0.763      0.537\n",
      "             surfboard          4          5      0.615        0.6      0.724      0.574\n",
      "         tennis racket          2          3       0.53          1      0.863      0.654\n",
      "                bottle         12         35      0.753      0.629       0.68      0.436\n",
      "            wine glass          4          7      0.477      0.429      0.366      0.239\n",
      "                   cup          9         26       0.79      0.654      0.778      0.586\n",
      "                  fork          1          2      0.599        0.5      0.526      0.466\n",
      "                 knife          3          3      0.666      0.667       0.71      0.566\n",
      "                 spoon          7         12      0.754      0.167      0.416      0.198\n",
      "                  bowl         10         18       0.75      0.667      0.708      0.495\n",
      "                banana          4         17      0.534      0.405      0.519      0.371\n",
      "                 apple          1          4      0.941       0.75      0.774      0.653\n",
      "              sandwich          1          2      0.325          1      0.828      0.696\n",
      "                orange          1          1      0.681          1      0.995      0.895\n",
      "              broccoli          1          2          1      0.866      0.995      0.796\n",
      "                carrot          2          5      0.254      0.282      0.216      0.144\n",
      "               hot dog          4         10       0.87        0.6      0.722      0.534\n",
      "                 pizza          5          5          1      0.711      0.843      0.511\n",
      "                 donut          1          1      0.116          1      0.995      0.995\n",
      "                  cake          5         11      0.421      0.455      0.506      0.446\n",
      "                 chair         15         57      0.708      0.439      0.543      0.368\n",
      "                 couch          4          4      0.748          1      0.995      0.695\n",
      "          potted plant          6          9      0.189      0.111      0.284      0.164\n",
      "                   bed          3          3      0.611      0.667      0.708      0.647\n",
      "          dining table         10         14      0.539       0.67      0.598      0.541\n",
      "                toilet          3          3      0.704          1      0.995      0.864\n",
      "                    tv          5          7          1      0.414      0.524      0.439\n",
      "                laptop          3          5      0.682        0.8      0.878      0.816\n",
      "                 mouse          3          3      0.626      0.667      0.452      0.419\n",
      "                remote          3          6      0.754        0.5      0.666      0.511\n",
      "              keyboard          3          4          1      0.578      0.945      0.857\n",
      "            cell phone          6          7      0.536      0.338      0.399      0.272\n",
      "             microwave          3          3      0.773          1      0.995      0.863\n",
      "                  oven          5          7       0.74      0.571      0.619       0.43\n",
      "               toaster          1          1      0.709          1      0.995      0.597\n",
      "                  sink          6          7      0.606      0.429      0.679      0.391\n",
      "          refrigerator          4         12          1      0.322      0.525      0.361\n",
      "                  book          2          2      0.339        0.5       0.39      0.358\n",
      "                 clock          2          2      0.692          1      0.995       0.92\n",
      "                  vase          6          7      0.341      0.286      0.449      0.332\n",
      "              scissors          1          1       0.62          1      0.995      0.995\n",
      "            teddy bear          2          2      0.632      0.897      0.663      0.376\n",
      "Speed: 1.1ms preprocess, 4.7ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1m/home/santana/MyStuff/assignments/dl-final-project/runs/detect/val\u001b[0m\n",
      "mAP50-95: 0.544779672556727\n",
      "mAP50: 0.7028838059361351\n",
      "mAP75: 0.5806711926574186\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load pretrained YOLOv8 on COCO\n",
    "model = YOLO(\"yolov8s.pt\")  # or yolov8n/m based on VRAM\n",
    "\n",
    "\n",
    "results = model.train(\n",
    "    data=\"data/coco_subset.yaml\",\n",
    "    epochs=6,\n",
    "    imgsz=640,\n",
    "    batch=16,          # shrink if OOM\n",
    "    device=0,          # or \"cuda:0\"\n",
    "    workers=4,\n",
    "    project=\"runs/coco\",\n",
    "    name=\"yolov8s_640_subset\",\n",
    ")\n",
    "\n",
    "# Validation on full val2017 (as per proposal)\n",
    "metrics = model.val(data=\"data/coco_subset.yaml\", split=\"val\")\n",
    "print(\"mAP50-95:\", metrics.box.map)\n",
    "print(\"mAP50:\", metrics.box.map50)\n",
    "print(\"mAP75:\", metrics.box.map75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae1cf42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/santana/MyStuff/assignments/dl-final-project/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "loading annotations into memory...\n",
      "Done (t=4.13s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.19s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train HF-DETR:   0%|          | 0/250 [00:00<?, ?it/s]It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "Train HF-DETR: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [00:54<00:00,  4.59it/s]\n",
      "Val HF-DETR (loss): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:07<00:00, 13.08it/s]\n",
      "Eval HF-DETR (COCO mAP): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:07<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.17s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.10s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.004\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.017\n",
      "[HF-DETR] Epoch 1/10 | train_loss=5.9101 | val_loss=4.9288 | AP=0.0016 | AP50=0.0042 | AP75=0.0000 | APs=0.0000 | APm=0.0000 | APl=0.0040\n",
      "  -> New best DETR model saved (AP=0.0016)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train HF-DETR: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [00:54<00:00,  4.57it/s]\n",
      "Val HF-DETR (loss): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:07<00:00, 13.18it/s]\n",
      "Eval HF-DETR (COCO mAP): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:07<00:00, 13.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.22s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.012\n",
      "[HF-DETR] Epoch 2/10 | train_loss=5.0237 | val_loss=5.0235 | AP=0.0002 | AP50=0.0004 | AP75=0.0002 | APs=0.0000 | APm=0.0000 | APl=0.0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train HF-DETR: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [00:54<00:00,  4.56it/s]\n",
      "Val HF-DETR (loss): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:07<00:00, 13.16it/s]\n",
      "Eval HF-DETR (COCO mAP): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:07<00:00, 13.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.22s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.010\n",
      "[HF-DETR] Epoch 3/10 | train_loss=5.0723 | val_loss=5.0153 | AP=0.0000 | AP50=0.0001 | AP75=0.0000 | APs=0.0001 | APm=0.0000 | APl=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train HF-DETR: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [00:55<00:00,  4.51it/s]\n",
      "Val HF-DETR (loss): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:07<00:00, 13.14it/s]\n",
      "Eval HF-DETR (COCO mAP): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:07<00:00, 13.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.23s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.09s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.020\n",
      "[HF-DETR] Epoch 4/10 | train_loss=4.8999 | val_loss=4.6553 | AP=0.0003 | AP50=0.0007 | AP75=0.0002 | APs=0.0000 | APm=0.0000 | APl=0.0009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train HF-DETR: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [00:55<00:00,  4.52it/s]\n",
      "Val HF-DETR (loss): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:07<00:00, 13.06it/s]\n",
      "Eval HF-DETR (COCO mAP): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:07<00:00, 13.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.23s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.006\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.016\n",
      "[HF-DETR] Epoch 5/10 | train_loss=4.8160 | val_loss=5.0177 | AP=0.0003 | AP50=0.0005 | AP75=0.0001 | APs=0.0000 | APm=0.0000 | APl=0.0007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train HF-DETR: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [00:54<00:00,  4.55it/s]\n",
      "Val HF-DETR (loss): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:07<00:00, 13.19it/s]\n",
      "Eval HF-DETR (COCO mAP): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:07<00:00, 13.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.23s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.012\n",
      "[HF-DETR] Epoch 6/10 | train_loss=4.8583 | val_loss=4.6483 | AP=0.0001 | AP50=0.0003 | AP75=0.0000 | APs=0.0000 | APm=0.0000 | APl=0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train HF-DETR: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [00:54<00:00,  4.55it/s]\n",
      "Val HF-DETR (loss): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:07<00:00, 13.06it/s]\n",
      "Eval HF-DETR (COCO mAP): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:07<00:00, 13.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.22s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.003\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.012\n",
      "[HF-DETR] Epoch 7/10 | train_loss=4.8042 | val_loss=4.7521 | AP=0.0001 | AP50=0.0004 | AP75=0.0001 | APs=0.0000 | APm=0.0000 | APl=0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train HF-DETR: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [00:54<00:00,  4.61it/s]\n",
      "Val HF-DETR (loss): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:07<00:00, 13.22it/s]\n",
      "Eval HF-DETR (COCO mAP): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:07<00:00, 13.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.23s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.005\n",
      "[HF-DETR] Epoch 8/10 | train_loss=4.8199 | val_loss=4.6436 | AP=0.0000 | AP50=0.0001 | AP75=0.0000 | APs=0.0000 | APm=0.0000 | APl=0.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train HF-DETR: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [00:54<00:00,  4.57it/s]\n",
      "Val HF-DETR (loss): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:07<00:00, 13.00it/s]\n",
      "Eval HF-DETR (COCO mAP): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:07<00:00, 13.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.23s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.002\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.007\n",
      "[HF-DETR] Epoch 9/10 | train_loss=4.7113 | val_loss=4.7334 | AP=0.0001 | AP50=0.0003 | AP75=0.0000 | APs=0.0000 | APm=0.0000 | APl=0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train HF-DETR: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 250/250 [00:54<00:00,  4.58it/s]\n",
      "Val HF-DETR (loss): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:07<00:00, 13.00it/s]\n",
      "Eval HF-DETR (COCO mAP): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:07<00:00, 13.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=1.11s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.08s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.005\n",
      "[HF-DETR] Epoch 10/10 | train_loss=4.7677 | val_loss=4.7012 | AP=0.0000 | AP50=0.0001 | AP75=0.0000 | APs=0.0000 | APm=0.0000 | APl=0.0001\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "from torch.utils.data import Subset  # <-- NEW\n",
    "\n",
    "from src.utils.coco_utils import make_coco_loaders\n",
    "\n",
    "def get_img_ids_for_loader(loader):\n",
    "    \"\"\"\n",
    "    Build a list img_ids such that:\n",
    "        img_ids[i] = COCO image_id corresponding to loader.dataset[i]\n",
    "\n",
    "    This walks through possible wrappers (Subset, custom DatasetWrapper, etc.)\n",
    "    and recovers the base COCO dataset's id list.\n",
    "    Assumes val_loader is created with shuffle=False.\n",
    "    \"\"\"\n",
    "    ds = loader.dataset\n",
    "\n",
    "    # Unwrap Subset and generic wrappers that store the underlying dataset in .dataset\n",
    "    indices = None  # indices in the base dataset\n",
    "    while True:\n",
    "        if isinstance(ds, Subset):\n",
    "            # Map current indices through this Subset\n",
    "            if indices is None:\n",
    "                indices = list(ds.indices)\n",
    "            else:\n",
    "                indices = [indices[i] for i in ds.indices]\n",
    "            ds = ds.dataset\n",
    "            continue\n",
    "\n",
    "        # handle \"wrapper.dataset\" style nesting (e.g. transforms)\n",
    "        if not hasattr(ds, \"coco\") and hasattr(ds, \"dataset\"):\n",
    "            ds = ds.dataset\n",
    "            continue\n",
    "\n",
    "        break\n",
    "\n",
    "    if not hasattr(ds, \"coco\"):\n",
    "        raise RuntimeError(\n",
    "            \"Could not find a base COCO dataset with a 'coco' attribute under loader.dataset\"\n",
    "        )\n",
    "\n",
    "    base_ds = ds  # this should be a CocoDetection-like dataset\n",
    "    coco = base_ds.coco\n",
    "\n",
    "    # Base indices (in base_ds) that correspond to loader order\n",
    "    if indices is None:\n",
    "        indices = list(range(len(base_ds)))\n",
    "\n",
    "    # Get the list of COCO image IDs in the same order as base_ds\n",
    "    if hasattr(base_ds, \"ids\"):\n",
    "        # Torchvision CocoDetection has .ids = list of image_ids\n",
    "        base_img_ids = list(base_ds.ids)\n",
    "    else:\n",
    "        # Fallback: use sorted COCO IDs (this is what CocoDetection does internally)\n",
    "        base_img_ids = list(sorted(coco.getImgIds()))\n",
    "\n",
    "    # Map loader index -> COCO image_id\n",
    "    loader_img_ids = [int(base_img_ids[i]) for i in indices]\n",
    "    return loader_img_ids\n",
    "\n",
    "\n",
    "\n",
    "def get_coco_api_from_loader(loader):\n",
    "    \"\"\"\n",
    "    Robustly get the underlying pycocotools COCO object from a DataLoader.\n",
    "    \"\"\"\n",
    "    ds = loader.dataset\n",
    "    for _ in range(10):\n",
    "        if hasattr(ds, \"coco\"):\n",
    "            return ds.coco\n",
    "        if hasattr(ds, \"dataset\"):\n",
    "            ds = ds.dataset\n",
    "        else:\n",
    "            break\n",
    "    raise AttributeError(\n",
    "        \"Could not find 'coco' attribute in dataset. \"\n",
    "        \"Please check make_coco_loaders implementation.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Helper: convert your targets (xyxy) ‚Üí COCO-style annotations\n",
    "# ------------------------------------------------------------\n",
    "def build_hf_targets(targets):\n",
    "    \"\"\"\n",
    "    Convert a batch of targets from your format:\n",
    "        {\n",
    "            \"boxes\": Tensor[num_boxes, 4] in xyxy,\n",
    "            \"labels\": Tensor[num_boxes],\n",
    "            (optionally \"image_id\", \"area\", \"iscrowd\")\n",
    "        }\n",
    "    into HuggingFace/COCO-style:\n",
    "        {\n",
    "            \"image_id\": int,\n",
    "            \"annotations\": [\n",
    "                {\"bbox\": [x, y, w, h], \"category_id\": int, \"area\": float, \"iscrowd\": 0/1},\n",
    "                ...\n",
    "            ]\n",
    "        }\n",
    "    \"\"\"\n",
    "    hf_targets = []\n",
    "\n",
    "    for t in targets:\n",
    "        boxes = t[\"boxes\"]  # (N, 4), xyxy\n",
    "        labels = t[\"labels\"]\n",
    "\n",
    "        if boxes.numel() == 0:\n",
    "            annotations = []\n",
    "        else:\n",
    "            # xyxy ‚Üí xywh\n",
    "            xywh = boxes.clone()\n",
    "            xywh[:, 2] = boxes[:, 2] - boxes[:, 0]  # w = x_max - x_min\n",
    "            xywh[:, 3] = boxes[:, 3] - boxes[:, 1]  # h = y_max - y_min\n",
    "\n",
    "            annotations = []\n",
    "            for box, label in zip(xywh, labels):\n",
    "                bbox = box.tolist()\n",
    "                category_id = int(label.item() if torch.is_tensor(label) else label)\n",
    "                ann = {\n",
    "                    \"bbox\": bbox,\n",
    "                    \"category_id\": category_id,\n",
    "                    \"area\": float(bbox[2] * bbox[3]),  # w * h\n",
    "                    \"iscrowd\": 0,\n",
    "                }\n",
    "                annotations.append(ann)\n",
    "\n",
    "        # Keep image_id if present, otherwise 0\n",
    "        if \"image_id\" in t:\n",
    "            if torch.is_tensor(t[\"image_id\"]):\n",
    "                image_id = int(t[\"image_id\"].item())\n",
    "            else:\n",
    "                image_id = int(t[\"image_id\"])\n",
    "        else:\n",
    "            image_id = 0\n",
    "\n",
    "        hf_targets.append({\n",
    "            \"image_id\": image_id,\n",
    "            \"annotations\": annotations,\n",
    "        })\n",
    "\n",
    "    return hf_targets\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Training loop for HuggingFace DETR\n",
    "# ------------------------------------------------------------\n",
    "def train_one_epoch_detr_hf(model, processor, loader, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, targets in tqdm(loader, desc=\"Train HF-DETR\"):\n",
    "        hf_targets = build_hf_targets(targets)\n",
    "\n",
    "        encoding = processor(\n",
    "            images=images,\n",
    "            annotations=hf_targets,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        pixel_values = encoding[\"pixel_values\"].to(device)\n",
    "        labels = [\n",
    "            {k: v.to(device) for k, v in target.items()}\n",
    "            for target in encoding[\"labels\"]\n",
    "        ]\n",
    "\n",
    "        outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Validation loss loop for HuggingFace DETR\n",
    "# ------------------------------------------------------------\n",
    "@torch.no_grad()\n",
    "def validate_one_epoch_detr_hf(model, processor, loader, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, targets in tqdm(loader, desc=\"Val HF-DETR (loss)\"):\n",
    "        hf_targets = build_hf_targets(targets)\n",
    "\n",
    "        encoding = processor(\n",
    "            images=images,\n",
    "            annotations=hf_targets,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        pixel_values = encoding[\"pixel_values\"].to(device)\n",
    "        labels = [\n",
    "            {k: v.to(device) for k, v in target.items()}\n",
    "            for target in encoding[\"labels\"]\n",
    "        ]\n",
    "\n",
    "        outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    return running_loss / len(loader)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# COCO mAP evaluation for HuggingFace DETR\n",
    "# ------------------------------------------------------------\n",
    "@torch.no_grad()\n",
    "def evaluate_coco_mAP_detr(model, processor, loader, device):\n",
    "    \"\"\"\n",
    "    COCO-style evaluation for HF DETR on *your subset* of val2017.\n",
    "\n",
    "    Fixes:\n",
    "      - Ensures image_ids in results match the subset used by the DataLoader.\n",
    "      - Maps DETR class indices -> COCO category_id using model.config.id2label\n",
    "        and coco.getCatIds(catNms=[name]).\n",
    "      - Restricts COCOeval to only those imgIds we actually predicted on.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    # --- COCO API + image-id mapping ---\n",
    "    coco = get_coco_api_from_loader(loader)\n",
    "    coco_img_ids_all = set(coco.getImgIds())\n",
    "\n",
    "    # loader_img_ids[i] = COCO image id for loader.dataset[i]\n",
    "    loader_img_ids = get_img_ids_for_loader(loader)\n",
    "    assert len(loader_img_ids) == len(loader.dataset), \\\n",
    "        \"Length mismatch between loader_img_ids and loader.dataset\"\n",
    "\n",
    "    # --- build mapping: DETR label index -> COCO category_id ---\n",
    "    # id2label is like {\"0\": \"N/A\", \"1\": \"person\", ...}\n",
    "    id2label = {int(k): v for k, v in model.config.id2label.items()}\n",
    "\n",
    "    label_idx_to_cat_id = {}\n",
    "    for idx, name in id2label.items():\n",
    "        # Some DETR classes may not exist in this COCO annotation file\n",
    "        cat_ids = coco.getCatIds(catNms=[name])\n",
    "        if len(cat_ids) > 0:\n",
    "            label_idx_to_cat_id[idx] = cat_ids[0]\n",
    "\n",
    "    if not label_idx_to_cat_id:\n",
    "        print(\"WARNING: could not map any DETR labels to COCO category ids.\")\n",
    "        return None\n",
    "\n",
    "    results = []\n",
    "    global_idx = 0  # position in loader_img_ids\n",
    "\n",
    "    for images, _targets in tqdm(loader, desc=\"Eval HF-DETR (COCO mAP)\"):\n",
    "        # images is a tuple; convert to list for processor\n",
    "        images = list(images)\n",
    "\n",
    "        # original H,W for each image\n",
    "        target_sizes = []\n",
    "        for img in images:\n",
    "            if isinstance(img, torch.Tensor):\n",
    "                h, w = img.shape[-2:]\n",
    "            else:  # PIL\n",
    "                w, h = img.size\n",
    "            target_sizes.append([h, w])\n",
    "\n",
    "        encoding = processor(images=images, return_tensors=\"pt\")\n",
    "        pixel_values = encoding[\"pixel_values\"].to(device)\n",
    "\n",
    "        outputs = model(pixel_values=pixel_values)\n",
    "        processed_outputs = processor.post_process_object_detection(\n",
    "            outputs=outputs,\n",
    "            target_sizes=torch.tensor(target_sizes, device=device),\n",
    "            threshold=0.0,   # keep all, COCOeval will handle scores\n",
    "        )\n",
    "\n",
    "        batch_size = len(processed_outputs)\n",
    "        batch_img_ids = loader_img_ids[global_idx: global_idx + batch_size]\n",
    "        global_idx += batch_size\n",
    "\n",
    "        for img_id, pred in zip(batch_img_ids, processed_outputs):\n",
    "            if img_id not in coco_img_ids_all:\n",
    "                # should not happen with correct mapping, but be safe\n",
    "                continue\n",
    "\n",
    "            boxes = pred[\"boxes\"].detach().cpu()\n",
    "            scores = pred[\"scores\"].detach().cpu()\n",
    "            labels = pred[\"labels\"].detach().cpu()\n",
    "\n",
    "            if boxes.numel() == 0:\n",
    "                continue\n",
    "\n",
    "            # xyxy -> xywh\n",
    "            boxes_xywh = boxes.clone()\n",
    "            boxes_xywh[:, 2] = boxes[:, 2] - boxes[:, 0]\n",
    "            boxes_xywh[:, 3] = boxes[:, 3] - boxes[:, 1]\n",
    "\n",
    "            for box, score, label in zip(boxes_xywh, scores, labels):\n",
    "                label_idx = int(label)\n",
    "\n",
    "                # skip labels not present in this COCO annotation\n",
    "                if label_idx not in label_idx_to_cat_id:\n",
    "                    continue\n",
    "\n",
    "                cat_id = int(label_idx_to_cat_id[label_idx])\n",
    "\n",
    "                results.append(\n",
    "                    {\n",
    "                        \"image_id\": int(img_id),\n",
    "                        \"category_id\": cat_id,\n",
    "                        \"bbox\": box.tolist(),\n",
    "                        \"score\": float(score),\n",
    "                    }\n",
    "                )\n",
    "\n",
    "    if not results:\n",
    "        print(\"No detections to evaluate (results list is empty).\")\n",
    "        return None\n",
    "\n",
    "    # --- COCOeval restricted to our subset of images ---\n",
    "    coco_dt = coco.loadRes(results)\n",
    "    coco_eval = COCOeval(coco, coco_dt, iouType=\"bbox\")\n",
    "\n",
    "    eval_img_ids = sorted({r[\"image_id\"] for r in results})\n",
    "    coco_eval.params.imgIds = eval_img_ids\n",
    "\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "\n",
    "    metrics = {\n",
    "        \"AP\":   float(coco_eval.stats[0]),\n",
    "        \"AP50\": float(coco_eval.stats[1]),\n",
    "        \"AP75\": float(coco_eval.stats[2]),\n",
    "        \"APs\":  float(coco_eval.stats[3]),\n",
    "        \"APm\":  float(coco_eval.stats[4]),\n",
    "        \"APl\":  float(coco_eval.stats[5]),\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Main: data, model, optimizer, training + validation + COCO mAP\n",
    "# ------------------------------------------------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "train_loader, val_loader = make_coco_loaders(\n",
    "    root=\"/mnt/ssd2/santana-coco/data/coco\",\n",
    "    batch_size=2,\n",
    "    num_workers=4,\n",
    "    train_limit=500,   # set to None for full train2017 per proposal\n",
    "    val_limit=100,     # set to None for full val2017 per proposal\n",
    ")\n",
    "\n",
    "processor = DetrImageProcessor.from_pretrained(\n",
    "    \"facebook/detr-resnet-50\",\n",
    "    revision=\"no_timm\",\n",
    ")\n",
    "model = DetrForObjectDetection.from_pretrained(\n",
    "    \"facebook/detr-resnet-50\",\n",
    "    revision=\"no_timm\",\n",
    ").to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "\n",
    "num_epochs = 10\n",
    "best_ap = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_one_epoch_detr_hf(\n",
    "        model=model,\n",
    "        processor=processor,\n",
    "        loader=train_loader,\n",
    "        optimizer=optimizer,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    val_loss = validate_one_epoch_detr_hf(\n",
    "        model=model,\n",
    "        processor=processor,\n",
    "        loader=val_loader,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    metrics = evaluate_coco_mAP_detr(\n",
    "        model=model,\n",
    "        processor=processor,\n",
    "        loader=val_loader,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    if metrics is not None:\n",
    "        ap = metrics[\"AP\"]\n",
    "        print(\n",
    "            f\"[HF-DETR] Epoch {epoch + 1}/{num_epochs} | \"\n",
    "            f\"train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | \"\n",
    "            f\"AP={ap:.4f} | AP50={metrics['AP50']:.4f} | \"\n",
    "            f\"AP75={metrics['AP75']:.4f} | APs={metrics['APs']:.4f} | \"\n",
    "            f\"APm={metrics['APm']:.4f} | APl={metrics['APl']:.4f}\"\n",
    "        )\n",
    "\n",
    "        if ap > best_ap:\n",
    "            best_ap = ap\n",
    "            torch.save(model.state_dict(), \"detr_hf_best.pth\")\n",
    "            print(f\"  -> New best DETR model saved (AP={ap:.4f})\")\n",
    "    else:\n",
    "        print(\n",
    "            f\"[HF-DETR] Epoch {epoch + 1}/{num_epochs} | \"\n",
    "            f\"train_loss={train_loss:.4f} | val_loss={val_loss:.4f} | \"\n",
    "            f\"no detections on val set\"\n",
    "        )\n",
    "\n",
    "    torch.save(model.state_dict(), f\"detr_hf_epoch{epoch + 1}.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
